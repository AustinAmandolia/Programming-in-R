---
title: "Programming in R Part II"
author: "Justin Post"
date: "August 9, 2017"
output: 
      ioslides_presentation:
         css: css/style.css
transition: faster
logo: img/logo.png
---

```{r,echo=FALSE,message=FALSE}
options(dplyr.print_min = 5)
library(knitr)
library(tidyverse)
library(Lahman)
```

## What do we want to be able to do?

- Restructure Data/Clean Data  

- Streamline repeated sections of code

- **Improve efficiency of code**  

- Write custom functions to simplify code 


## Efficient Code  

For loops inefficient in R  

> + R interpreted language  

> + Must figure out how to evaluate code at each iteration of loop  

> + Slows it down  


## Efficient Code  

For loops inefficient in R  

 + R interpretted language  

 + Must figure out how to evaluate code at each iteration of loop  
 
 + Slows it down  

Vecotrized functions much faster!  

> + Vectorized function: works on entire vector at once  

> + Avoids costly computation time  
    

## Efficient Code  

Some 'built-in' vectorized functions    

> + `colMeans()`, `rowMeans()`
> + `colSums()`, `rowSums()`
> + `colSds()`, `colVars()`, `colMedians()` (`matrixStats` package)
> + `ifelse()` 
> + `apply()` family

> + Create your own with `Vectorize()`


## Efficient Code  

- Find column means for full Batting data set

- `colMeans()` just requires a numeric data frame (array)

```{r}
colMeans(select(Batting, G:GIDP), na.rm = TRUE)
```

## Efficient Code

- Compare computational time  

- `microbenchmark` package allows for easy recording of computing time

```{r,eval=FALSE}
install.packages("microbenchmarK")
```
```{r}
library(microbenchmark)
```


## Efficient Code

- Compare computational time  

```{r}
Bat <- select(Batting, G:GIDP)
microbenchmark(
  colMeans(Bat, na.rm = TRUE)
)
```

## Efficient Code

- Compare computational time  

```{r}
microbenchmark(
  for(i in 1:17){
    mean(Bat[ , i], na.rm = TRUE)
  }
)
```


## Efficient Code  

- With vectorized functions, can easily find cool stuff

> - Median number of games played for all players

> - Median number of AB for players that batted

> - Steps: (think `dplyr` commands!)   

> 1. Group observations by playerID 
> 2. Summarise variables of interest
> 3. Remove non numeric column
> 4. Coerce to matrix for use in `colMedians()`
> 5. Use `colMedians()` function


## Efficient Code  
    
```{r,eval=TRUE}
library(matrixStats) #install if not installed

Batting %>% group_by(playerID) %>%
  summarise(totG = sum(G), totAB = sum(AB)) %>% 
  select(-playerID) %>% as.matrix() %>%
  colMedians(na.rm = TRUE)
```
<br>
<br>
<br>

> - Next up, `ifelse()`


## Efficient Code

- Logical statement - comparison of two quantities  
    + resolves as TRUE or FALSE  

> -  Often want to execute code logically  

> - logical comparison operators 
    <ul>
      <li> `==`, `!=`, `>=`, `<=`, `>`, `<` </li>
      <li> `&` "and"</li>
      <li> `|` "or" </li>
    </ul>

> -  logical functions 
    <ul><li> `is.` family (`is.numeric()`, `is.data.frame()`, etc.) </li></ul>


## Efficient Code
**If then, If then else**

- Often want to execute statements conditionally  
- If then else concept
```{r,eval=FALSE}
if (condition) {
  then execute code
} 

#if then else
if (condition) {
  execute this code  
} else {
  execute this code
}
```


## Efficient Code
**If then, If then else**

- Often want to execute statements conditionally  
- If then else concept
```{r,eval=FALSE}
#Or more if statements
if (condition) {
  execute this code  
} else if (condition2) {
  execute this code
} else if (condition3) {
  execute this code
} else {
  #if no conditions met
  execute this code
}
```


## Efficient Code

- Often create new variables


## Efficient Code

- Often create new variables

- Built in data set `airquality`  
    + daily air quality measurements in New York
    + from May (Day 1) to September (Day 153) in 1973 
```{r}
airquality<-tbl_df(airquality)
airquality
```


## Efficient Code

Want to code a wind category variable    

> + high wind days (15mph $\leq$ wind)  
> + windy days     (10mph $\leq$ wind < 15mph)  
> + lightwind days (6mph $\leq$ wind < 10mph)  
> + calm days      (wind $\leq$ 6mph)


## Efficient Code

Want to code a wind category variable    

 + high wind days (15mph $\leq$ wind)  
 + windy days     (10mph $\leq$ wind < 15mph)  
 + lightwind days (6mph $\leq$ wind < 10mph)  
 + calm days      (wind $\leq$ 6mph)  
 
Initial plan    

  + loop through each observation    
  
  + use if then else to determine wind status    
  
    

## Efficient Code

```{r}
#initialize vector to save results
status<-vector()

for (i in 1:(dim(airquality)[1])){
  if(airquality$Wind[i] >= 15){
    status[i] <- "HighWind"
  } else if (airquality$Wind[i] >= 10){
    status[i] <- "Windy"
  } else if (airquality$Wind[i] >= 6){
    status[i] <- "LightWind"
  } else if (airquality$Wind[i] >= 0){
    status[i] <- "Calm"
  } else {
    status[i] <- "Error"
  }
}
```

## Efficient Code

```{r}
status
```


## Efficient Code

- Add it to the data set 
```{r,eval=FALSE}
airquality$status <- status
```

- Find mean temperature for each wind Status
```{r,eval=FALSE}
airquality$status <- status
airquality %>% group_by(status) %>%
  mutate(avgTemp = mean(Temp))
```


## Efficient Code

```{r,eval=TRUE,echo=FALSE}
airquality$status<-status
airquality %>% group_by(status) %>%
  mutate(avgTemp=mean(Temp))
```


## Efficient Code  

- Know for loops not great  

- `ifelse()` is vectorized version of `if then else`

- Syntax

```{r,eval=FALSE}
ifelse(vector_condition, if_true_do_this, if_false_do_this)
```


## Efficient Code

```{r}
ifelse(airquality$Wind >= 15, "HighWind",
          ifelse(airquality$Wind >= 10, "Windy",
                 ifelse(airquality$Wind >= 6, "LightWind", "Calm")))
```


## Efficient Code

- Compare speed
```{r}
loopTime<-microbenchmark(
  for (i in 1:(dim(airquality)[1])){
    if(airquality$Wind[i] >= 15){
      status[i] <- "HighWind"
    } else if (airquality$Wind[i] >= 10){
      status[i] <- "Windy"
    } else if (airquality$Wind[i] >= 6){
      status[i] <- "LightWind"
    } else if (airquality$Wind[i] >= 0){
      status[i] <- "Calm"
    } else{
      status[i] <- "Error"
    }
  }
, unit = "us")
```


## Efficient Code

- Compare speed

```{r}
vectorTime <- microbenchmark(
  ifelse(airquality$Wind >= 15, "HighWind",
            ifelse(airquality$Wind >= 10, "Windy",
                   ifelse(airquality$Wind >= 6, "LightWind", "Calm")))
, unit = "us")
```

##Efficient Code (Note units!)

```{r}
loopTime
vectorTime
```

## Efficient Code

- `apply()` family of functions *pretty* fast

> - Check `help(apply)` 
    <ul><li> We'll look at `apply()`, `sapply()`, `lapply()`</li><ul>


## Efficient Code

- `apply()` family of functions *pretty* fast

 - Check `help(apply)` 
    <ul><li> We'll look at `apply()`, `sapply()`, `lapply()`</li><ul>    
    
 - Use `apply()` to find summary for columns of airquality data

```{r,eval=FALSE}
apply(X = select(airquality, Ozone:Temp), MARGIN = 2, 
      FUN = summary, na.rm = TRUE)
```

## Efficient Code

- Keeps data numeric, keeps labels!

```{r,eval=TRUE,echo=FALSE}
apply(X=select(airquality,Ozone:Temp),MARGIN=2,FUN=summary,na.rm=TRUE)
```


## Efficient Code

- Use `lapply()` to apply function to lists

- Obtain a list object  

```{r}
fit <- lm(Ozone ~ Wind, data = airquality)
fit <- list(fit$residuals, fit$effects, fit$fitted.values)
```

## Efficient Code

```{r}
fit[[1]]
```

## Efficient Code

```{r}
fit[[2]]
```

## Efficient Code

- Apply `mean()` function to each list element

```{r}
lapply(X = fit, FUN = mean)
```


##Efficient Code

- Use `sapply()` similar but returns a vector if possible

```{r}
sapply(X = fit, FUN = mean)
```

----

- `apply()` functions not as good as `colMeans()` type functions
```{r}
air2 <- select(airquality, Ozone:Day)
microbenchmark(apply(X = air2, MARGIN = 2, FUN = mean, na.rm = TRUE))
microbenchmark(colMeans(air2, na.rm = TRUE))
```


## Recap!

- Vectorized functions fast!

- 'Built-in' vectorized functions  
    + `colMeans()`, `rowMeans()`
    + `colSums()`, `rowSums()`
    + `colSds()`, `colVars()`, `colMedians()` (`matrixStats` package)
    + `ifelse()` 
    + `apply()` family


## Activity 
- [**Vectorized Functions Activity** instructions](http://www4.stat.ncsu.edu/~post/ProgrammingR/VectorizedActivity.html) available on web  

- Work in small groups  

- Ask questions!  TAs and I will float about the room  

- Feel free to ask questions about anything you didn't understand as well!   


## What do we want to be able to do?

- Restructure Data/Clean Data  

- Streamline repeated sections of code

- Improve efficiency of code  

- **Write custom functions to simplify code** 


## Writing Functions

- Knowing how to write **functions** vital to custom analyses!  

- Function writing syntax

```{r,eval=FALSE}
nameOfFunction <- function(input1, input2, ...) {
  #code
  #return something with return()
  #or returns last value
}
```

## Writing Functions

- Can look at code for functions

```{r}
var
```

## Writing Functions

- Can look at code for functions

```{r}
colMeans
```


## Writing Functions

- Can look at code for functions

```{r}
mean
```

## Writing Functions

- Can look at code for functions

```{r}
mean.default
```

## Writing Functions

- Goal: Create a `standardize()` function   

- Take vector of values  
    + subtract mean 
    + divide by standard deviation  
    
- z-score idea

- Formula: For value i,

      (value[i] - mean(value)) / sd(value)


## Writing Functions

```{r,eval=FALSE}
nameOfFunction <- function(input1, input2, ...) {
  #code
  #return something with return()
  #or returns last value
}
```
```{r}
standardize <- function(vector) {
  return((vector - mean(vector)) / sd(vector))
}
```


## Writing Functions

- Now use it!

```{r}
data <- runif(5)

data

result <- standardize(data)

result
```

## Writing Functions

- Check result has mean 0 and sd 1
```{r}
mean(result)
sd(result)
```

## Writing Functions

- Goal: Add more inputs
- Make centering optional
- Make scaling optional

```{r}
standardize <- function(vector, center, scale) {
  if (center == TRUE) {
    vector <- vector - mean(vector)
  }
  if (scale == TRUE) {
    vector <- vector / sd(vector)
  } 
  return(vector)
}
```

## Writing Functions

```{r}
result <- standardize(data, center = TRUE, scale = TRUE)
result

result <- standardize(data, center = FALSE, scale = TRUE)
result
```

## Writing Functions

- Give center and scale default arguments

```{r}
standardize <- function(vector, center = TRUE, scale = TRUE) {
  #center and scale if appropriate
  if (center == TRUE) {
    vector <- vector - mean(vector)
  }
  if (scale == TRUE) {
    vector <- vector / sd(vector)
  } 
  return(vector)
}
```


## Writing Functions

```{r}
result <- standardize(data, center = TRUE, scale = TRUE)
result

#same call
result <- standardize(data)
result
```


## Writing Functions

- Return more than 1 object by returning a list

- Goal: Also return   
     + `mean()` of original data  
     + `sd()` of original data
     

## Writing Functions

```{r}
standardize <- function(vector, center = TRUE, scale = TRUE) {
  #get attributes to return
  mean <- mean(vector)
  stdev <- sd(vector)
  #center and scale if appropriate
  if (center == TRUE) {
    vector <- vector - mean
  }
  if (scale == TRUE) {
    vector <- vector / stdev
  } 
  #return a list of objects
  return(list(vector, mean, stdev))
}
```


## Writing Function

```{r}
result <- standardize(data)
result
result[[2]]
```

## Writing Functions

- Fancy up what we return by giving names
```{r}
standardize <- function(vector, center = TRUE, scale = TRUE) {
  #get attributes to return
  mean <- mean(vector)
  stdev <- sd(vector)
  #center and scale if appropriate
  if (center == TRUE) {
    vector <- vector - mean
  }
  if (scale == TRUE) {
    vector <- vector / stdev
  } 
  #return a list of objects
  return(list(result = vector, mean = mean, sd = stdev))
}
```

## Writing Functions

```{r}
result <- standardize(data, center = TRUE, scale = TRUE)
result
result$sd
```


## Writing Functions  

- Can bring in unnamed arguments  
- Arguments that can be used by functions **inside** your function  
- Done already in `apply()`

```{r}
apply
```


## Writing Functions  

```{r}
apply(X = select(airquality, Ozone:Temp), MARGIN = 2, 
      FUN = summary, na.rm = TRUE)
```

## Writing Functions

- Add unnamed arguments to our function
```{r}
standardize <- function(vector, center = TRUE, scale = TRUE, ...) {
  #get attributes to return
  mean <- mean(vector, ...)
  stdev <- sd(vector, ...)
  #center and scale if appropriate
  if (center == TRUE) {
    vector <- vector - mean
  }
  if (scale == TRUE) {
    vector <- vector / stdev
  } 
  #return a list of objects
  return(list(result = vector, mean = mean, sd = stdev))
}
```

## Writing Functions  

```{r}
sData <- standardize(airquality$Ozone, na.rm = TRUE)
sData$mean
sData$sd
sData$result
```

## Recap!

- Function writing opens R up!

- Syntax
```{r,eval=FALSE}
nameOfFunction <- function(input1, input2, ...) {
  #code
  #return something with return()
  #or returns last value
}
```

- Can set defaults in function definition

- Can return a named list

- Can give unnamed arguments for use


## Activity 
- [**Function Writing Activity** instructions](http://www4.stat.ncsu.edu/~post/ProgrammingR/FunctionActivity.html) available on web  

- Work in small groups  

- Ask questions!  TAs and I will float about the room  

- Feel free to ask questions about anything you didn't understand as well!   


## What do we want to be able to do?

- Restructure Data/Clean Data  

- Streamline repeated sections of code

- **Improve efficiency of code**  

- Write custom functions to simplify code



## Parallel Computing

- Just basic intro and idea (very complicated, many things to consider!)

Idea:    

> + Take computations that can be done independently (or close to it)
> + Don't run sequentially  
> + Split up computation
> + Run computation simultaneously on 
      <ul>
        <li> different processor cores</li>  
        <li> across many connected computers (i.e. on a cluster)</li>
        <li> or a few other ways</li>
      </ul>  
> + Combine results


## Parallel Computing

Many applications in data science lend themselves to parallel computing 

Examples  

> + Monte Carlo simulation studies
> + Bootstrapping
> + Multiple MCMC runs from different starting points
> + Cross Validation
> + Random Forests and Boosting algorithms
<br>
<br>
> - We'll use `parallel` package (built-in)



## Parallel Computing

- `parallel` package function we'll use has syntax similar to `apply()` family  

- Problem to parallelize:
    + kmeans clustering
        * group similar observations
    + consider iris data set

```{r}
iris<-tbl_df(iris)
```

##Parallel Computing

```{r}
iris
```


## Parallel Computing

- Problem to parallelize:
    + kmeans clustering
        * group similar observations


```{r,eval=FALSE}
library(fpc)       #install if needed
iris$Species <- NULL #remove category labels (truly 3 groups)
clus <- kmeans(iris, centers = 3, nstart = 100)
plotcluster(iris, clus$cluster)
```


## Parallel Computing

```{r,eval=TRUE,echo=FALSE}
library(fpc)       #install if needed
iris$Species<-NULL #remove category labels (truely 3 groups)
clus<-kmeans(iris,centers=3,nstart=100)
plotcluster(iris, clus$cluster)
```

## Parallel Computing

Why is this able to be parallelized?  

> + Code tries to find 3 'cluster' centers using 100 random starting positions
> + Result is the starting position that yields the minimal `result$tot.withinss` value
> + Each random starting point used is independent of the others (embarrassingly parallel)  
> + Can assign some of the runs of the algorithm to separate computer cores  
> + Combine back at the end, look at overall smallest value


## Parallel Computing

- How to parallelize this?

- Create a function using lapply to do the kmeans call

```{r}
parallel.function <- function(data, i) {
  kmeans(as.matrix(data), centers = 3, nstart = i)
}
```

## Parallel Computing

- Evaluating example with lapply

```{r}
results <- lapply(X = c(25, 25), FUN = parallel.function, data = iris)
```

## Parallel Computing

```{r}
results[[1]]
```

## Parallel Computing

```{r}
results[[2]]
```

<!--lapply will call the function we made 2 times, each with 25 starting points (for a total of 50)
#returns a list of 4 things with the results for each function call-->


## Parallel Computing  

- Want best result of the two returned


## Parallel Computing  

- Want best result of the two returned

- Create a function to determine which call had the best overall result

```{r}
temp.vector <- sapply(results, function(result) {result$tot.withinss})
#take the result for the best one as the final solution
result <- results[[which.min(temp.vector)]]
print(result)
```

## Parallel Computing

- Set-up is a lot of work!  

> - For a large problem this could save a lot of time.
> - Now parallelize it
    <ul> 
      <li> Set up cores</li>
      <li> Only code change: use `parLapply()` insead of `lapply()`</li>
    </ul>


## Parallel Computing

- Set-up is a lot of work!

- For a large problem this could save a lot of time.
- Now parallelize it
    + Set up cores
    + Only code change: use `parLapply()` insead of `lapply()`

```{r,eval=FALSE,message=FALSE}
library(parallel)
cores <- detectCores()
cluster <- makeCluster(cores - 1)
results <- parLapply(cluster, X = c(250, 250, 250),
                     fun = parallel.function, data = iris)
temp.vector <- sapply(results, function(result) {result$tot.withinss})
result <- results[[which.min(temp.vector)]]
print(result)
```


## Parallel Computing

```{r,eval=TRUE,echo=FALSE,message=FALSE}
library(parallel)
cores <- detectCores()
cluster <- makeCluster(cores-1)
results <- parLapply(cluster,X=c(250, 250, 250),
                    fun=parallel.function,data=iris)
temp.vector <- sapply( results, function(result) {
  result$tot.withinss } )
result <- results[[which.min(temp.vector)]]
print(result)
```

## Parallel Computing

- Compare computation time when parallelized
```{r,eval=TRUE, message=FALSE,warning=FALSE}
parTime <- microbenchmark({
  library(parallel)
  cores <- detectCores()
  cluster <- makeCluster(cores - 1)
  results <- parLapply(cluster, X = c(25000, 25000, 25000),
                    fun = parallel.function, data = iris)
  temp.vector <- sapply(results, function(result) {result$tot.withinss})
  result <- results[[which.min(temp.vector)]]
}, times = 10, unit = "s")

straightTime <- microbenchmark({
  clus <- kmeans(iris, centers = 3, nstart = 75000)
}, times = 10, unit = "s")
```

## Parallel Computing

```{r}
parTime
straightTime
```


## Recap!

- Parallel Computing can speed up computations

- A lot of up front work

- Can only use when process can be done separately

- Many other ways to speed up R as well (see Microsoft R)


## What do we want to be able to do?

- Restructure Data/Clean Data  

- Streamline repeated sections of code  

- Improve efficiency of code  

- Write custom functions to simplify code  

- Thanks for coming!
